{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A rough attempt to match receipt to record using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from util_bill import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"Bill.com/Users.csv\")\n",
    "\n",
    "# add a prediction column\n",
    "users[\"prediction\"] = [0 for i in range(len(users))]\n",
    "\n",
    "import os\n",
    "filesList = os.listdir(\"./Bill.com/ocr/\")\n",
    "file_id_list = [s[:-4] for s in filesList]\n",
    "\n",
    "file_id_list.remove(\".DS_S\") # this one is not csv\n",
    "\n",
    "def read_ocr(file):\n",
    "    '''read one orc file into pandas dataframe'''\n",
    "\n",
    "    data = {\"x1\":[], \"y1\":[],\"x2\":[], \"y2\":[],\"x3\":[], \"y3\":[],\"x4\":[], \"y4\":[], \"value\":[]}\n",
    "    with open(file) as f:\n",
    "         lines = f.readlines()\n",
    "\n",
    "         for line in lines:\n",
    "            row = line.split(',', 8)\n",
    "\n",
    "            data['x1'].append(row[0])\n",
    "            data['y1'].append(row[1])\n",
    "            data['x2'].append(row[2])\n",
    "            data['y2'].append(row[3])\n",
    "            data['x3'].append(row[4])\n",
    "            data['y3'].append(row[5])\n",
    "            data['x4'].append(row[6])\n",
    "            data['y4'].append(row[7])\n",
    "            data['value'].append(row[8])\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bag of words for each row in users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words(strings):\n",
    "  bag = []\n",
    "  for sent in strings:\n",
    "    bag += sent.lower().split(\" \")\n",
    "  return bag\n",
    "\n",
    "BOW_users = []\n",
    "\n",
    "for i in range(len(users)):\n",
    "    temp_strings = [users.iloc[i][s] for s in [\"vendor_name\",\"vendor_address\",\"date\"]]\n",
    "    BOW_users.append(get_bag_of_words(temp_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the bag of words similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x,y):\n",
    "  \"\"\"\n",
    "  returns the jaccard similarity between two lists\n",
    "  \n",
    "  copied from https://newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python\n",
    "  \"\"\"\n",
    "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "  return intersection_cardinality/float(union_cardinality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(file_id, path = \"./Bill.com/ocr/\", BOW_users = BOW_users, users_df = users):\n",
    "    file = path+ file_id + \".csv\"\n",
    "    value_df = read_ocr(file)[\"value\"]\n",
    "    bag_strings = []\n",
    "    for i in range(len(value_df)):\n",
    "        bag_strings.append(value_df.iloc[i][:-1])\n",
    "    BOW_file = get_bag_of_words(bag_strings)\n",
    "\n",
    "    similarity = []\n",
    "    for i in range(len(BOW_users)):\n",
    "        similarity.append(jaccard_similarity(BOW_file, BOW_users[i]))\n",
    "\n",
    "    max_loc = np.argmax(similarity)\n",
    "    # print(max_loc, file_id)\n",
    "    users_df.loc[max_loc,[\"prediction\"]] = file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.93 s, sys: 68.8 ms, total: 2.99 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for file_id in file_id_list:\n",
    "    predict_one(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.29458917835671344\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(df):\n",
    "    '''\n",
    "    calculate the fraction of correction prediction\n",
    "\n",
    "    df should have a column named \"document\"\n",
    "    '''\n",
    "    num_correct = np.sum(df[\"prediction\"] == df[\"documentid\"])\n",
    "    return float(num_correct/len(df))\n",
    "\n",
    "print(\"Accuracy: \", calculate_accuracy(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('TA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f05e1f036679d9f6b0c649b8f00afc2e28cd2a1941d5293edd84c83f5ab7d3b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
